<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-175023497-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-175023497-1');
  </script>

  <title>Vít Růžička</title>
  
  <meta name="author" content="Vit Ruzicka">
  <meta name="keywords" content="Vit Ruzicka, machine learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="stylesheet"  href="css/lightslider.css"/>
  <link rel="icon" type="image/png" href="images/previtus.png">

  <!--<script src="http://code.jquery.com/jquery-1.11.0.js"></script>-->
  <!--<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>-->
  <script src="js/jquery.1.9.1.min.js"></script>

</head>

<body>
  <table id="main_page_list"><tbody>
    <tr>
      <td>

        <table><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p class="menu_select">
                <a href="index.html" title="Research, Artworks & info">Main</a> | <a href="photo.html">Photography</a> | Etc.
              </p>
            </td>
          </tr>
        </tbody></table>

	  
        <table><tbody>
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Vít Růžička</name>
              </p>
              <p>Welcome to my webpage, here are few details about me, my projects in academia and photography. Currently, I am a DPhil student at the Department of Computer Science at the <a href="https://www.ox.ac.uk/">University of Oxford</a>, supervised by <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/">Niki Trigoni</a> and <a href="https://www.cs.ox.ac.uk/people/andrew.markham/">Andrew Markham</a>. In 2019-20, I was working as a research assistant and lecturer at the University of the Arts London in the <a href="https://www.arts.ac.uk/creative-computing-institute">Creative Computing Institute</a>. Before that I was on a research internship at ETH Zurich in the <a href="https://prs.igp.ethz.ch/ecovision.html">EcoVision group</a> (2019) and at Carnegie Mellon University in <a href="https://users.ece.cmu.edu/~franzf/" title="The awesome IAESTE is responsible for this particular internship. They offer positions in academia and industry around the world for freshly finished students of technical disciplines. I highly recommend checking them out!">Franz Franchetti’s group</a> (2017-18). I did my MSc and BSc at the <a href="https://oi.fel.cvut.cz/en/" title="I am endlessly grateful to the study abroad program conducted by CTU/ČVUT. Feel free to contact me with questions on how to apply for it.">Czech Technical University in Prague</a>. Recently, I have been working with Frontier Development Lab, as a researcher in <a href="https://fdleurope.org/fdl-europe-2021">FDL Europe 2021</a> and as a Machine Learning team lead in <a href="https://frontierdevelopmentlab.org/fdl2022">FDL USA 2022</a>. In the summer of 2023, I also did an internship at the <a href="https://philab.esa.int/">ESA Φ-lab</a>. I like Machine Learning research, Arts, literature, traveling and analog photography.
              </p>
              <p style="text-align:center">
                <a href="mailto:previtus@gmail.com">Email</a> &nbsp/&nbsp
                <!--<a href="cv.pdf">CV</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=sNK00NIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/previtus">GitHub</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/previtus">YouTube</a> &nbsp/&nbsp
                <a href="https://www.cs.ox.ac.uk/people/vit.ruzicka/" title="University of Oxford"><img src="logos/ox.ico" width="20px"></a>
                <a href="https://researchers.arts.ac.uk/2218-vit-ruzicka/about" title="University of the Arts London"><img src="logos/ual.ico" width="20px"></a>
              </p>

  <!--demo for the in-line pop-up: <p>
    aaa <a href="#" class="trigger">this link</a><span id="pop-up">This box only appears when the trigger link is hovered over. Otherwise it is hidden from view.</span> bbb ccc <a href="#" class="trigger">this link</a><span id="pop-up">Alternative box.</span> bbb
  </p>-->
            </td>
            <td style="padding:2.5%;width:20%;max-width:20%">
              <a href="images/vr02_hq.jpg"><img style="width:100%;max-width:100%" alt="profile photo" title="Foto by Štefan Berec from 2023" src="images/vr02.jpg"></a>
            </td>
          </tr>
        </tbody></table>


        <table><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <div class="heading">Featured research</div>
              <p>My research interests are in Machine Learning applied in image analysis and generation, Computer Vision and Generative Models, often in the area of Remote Sensing. For the full list of my publications please check my <a href="https://scholar.google.com/citations?user=sNK00NIAAAAJ">Google Scholar</a> profile, few selected works are listed here.
              </p>
            </td>
          </tr>
        </tbody></table>
		
        <table><tbody>
<!-- paper -->
          <tr onmouseout="p_starcop_stop()" onmouseover="p_starcop_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41598-023-44918-6">
			        <papertitle>Semantic Segmentation of Methane Plumes with Hyperspectral Machine Learning Models</papertitle>
              </a>
			  <br>
              <strong>Vít Růžička</strong>, <a href="https://www.uv.es/gonmagar/">Gonzalo Mateo-Garcia</a>, <a href="https://www.uv.es/chovago/">Luis Gómez-Chova</a>, <a href="https://scholar.google.com/citations?user=oO-dzBoAAAAJ">Anna Vaughan</a>, <a href="https://luiguapa.webs.upv.es/">Luis Guanter</a>, <a href="https://www.cs.ox.ac.uk/people/andrew.markham/">Andrew Markham</a>
              <br>
			         <strong><em>Nature Scientific Reports</em></strong>, 2023; ECMWF–ESA workshop, 2022
              <br>
			        <a href="https://github.com/spaceml-org/STARCOP">code</a> and <a href="https://zenodo.org/records/7863343">data</a>
              / ECMWF–ESA workshop:
		          <a href="https://events.ecmwf.int/event/304/contributions/3628/attachments/2152/3811/ECMWf-ESA-ML_Ruzicka.pdf">presentation</a>
              /
              <a href="https://vimeo.com/771105606/c1cddccabb">video</a>
              /
              <a href="https://www.cs.ox.ac.uk/news/2218-full.html">media</a>
              <p></p>
              <p>We introduce a new dataset of hyperspectral images from the AVIRIS sensor with refined methane labels. We propose lightweight machine learning models for semantic segmentation of methane plumes, which outperform the classical baselines. We show zero-shot generalisation in the new EMIT hyperspectral sensor. More details will be released soon, alongside the code and the dataset. Work conducted through the Trillium Technologies here: <a href="https://trillium.tech/starcop" title="Trillium Technologies, Automated Methane plume monitoring from orbit.">STARCOP</a>.
			  </p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_starcop_image'>
                  <img class="bigimg" src='images/paper_starcop_methane_detection_predictions.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_starcop_methane_detection.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_starcop_start() { document.getElementById('p_starcop_image').style.opacity = "1"; }
                function p_starcop_stop() { document.getElementById('p_starcop_image').style.opacity = "0"; }
                p_starcop_stop()
              </script>
            </td>
          </tr> 
<!-- / paper -->
        </tbody></table>
		
        <table><tbody>
<!-- paper -->
          <tr onmouseout="p_fdl_fire_stop()" onmouseover="p_fdl_fire_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_fdl_fire'>
                  <img class="bigimg" src='images/paper_fireclr_prediction.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_fireclr.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_fdl_fire_start() { document.getElementById('p_fdl_fire').style.opacity = "1"; }
                function p_fdl_fire_stop() { document.getElementById('p_fdl_fire').style.opacity = "0"; }
                p_fdl_fire_stop()
              </script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle">
		    
			  <a href="https://arxiv.org/abs/2211.14654">
              <papertitle>Unsupervised Wildfire Change Detection based on Contrastive Learning</papertitle>
			  </a>
              <br>
<a href="https://drought.unl.edu/AboutUs/WhoWeAre.aspx?id=43">Beichen Zhang</a>, <a href="https://twitter.com/huiqi_wang56">Huiqi Wang</a>, <a href="https://scholar.google.com/citations?user=XvF18AkAAAAJ&hl=en">Amani Alabri</a>, <a href="https://www.researchgate.net/profile/Karol-Bot-2">Karol Bot</a>, <a href="https://www.researchgate.net/profile/Cole-Mccall">Cole McCall</a>, <a href="https://www.researchgate.net/profile/Dale-Hamilton-2">Dale Hamilton</a>, <strong>Vít Růžička</strong>
              <br>
			  <em>NeurIPS Workshop on AI for Humanitarian Assistance and Disaster Response Workshop (AI+HADR)</em>, 2022
              <br>
              <a href="https://github.com/spaceml-org/FireCLR-Wildfires">code</a>

              <p></p>
              <p>We show how to apply the contrastive learning technique of SimCLR for the task of unsupervised change detection, exemplified on wildfire detection. For this project, I was the ML team lead at the <a href="https://frontierdevelopmentlab.org/neurips2022">FDL US 2022</a>.</p>
            </td>
          </tr> 
<!-- / paper -->
        </tbody></table>
	
        <table><tbody>
<!-- paper -->
          <tr onmouseout="p_fdl_aihadr_stop()" onmouseover="p_fdl_aihadr_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
			  <a href="https://www.nature.com/articles/s41598-022-19437-5">
                 <papertitle>RaVÆn: unsupervised change detection of extreme events using ML on-board satellites</papertitle>
			  </a>
              <br>
              <strong>Vít Růžička</strong>, <a href="https://scholar.google.com/citations?user=oO-dzBoAAAAJ">Anna Vaughan</a>, <a href="https://www.kellogg.ox.ac.uk/our-people/daniele-de-martini/">Daniele De Martini</a>, <a href="https://dfulu.github.io/">James Fulton</a>, <a href="https://www.seti.org/affiliates/valentina-salvatelli">Valentina Salvatelli</a>, <a href="https://www.surrey.ac.uk/people/chris-bridges">Chris Bridges</a>, <a href="https://www.uv.es/gonmagar/">Gonzalo Mateo-Garcia</a>, <a href="https://vzantedeschi.com/">Valentina Zantedeschi</a>
              <br>
			  <strong><em>Nature Scientific Reports</em></strong>, 2022; 
			  <em>NeurIPS Workshop on AI for Humanitarian Assistance and Disaster Response Workshop (AI+HADR)</em>, 2021
              <br>
			  <a href="https://github.com/spaceml-org/RaVAEn/">code & data</a>
        /
              <a href="data/presentation_UnsupervisedChangeDetection_AIHADR2021.pdf" class="trigger">presentation slides</a><span id="pop-up" style="width: 400px;"><b>Presentation at AI+HADR'21:</b><br>&nbsp;<img src="data/presentation_UnsupervisedChangeDetection_AIHADR2021.png" width=400px></span>
        /
              <a href="https://www.youtube.com/watch?v=ALtYfcuLzxI">video from AI+HADR'21</a>
        /
              <a href="https://www.ox.ac.uk/news/2023-07-28-researchers-successfully-train-machine-learning-model-outer-space-first-time">media 1</a>, <a href="https://www.scan.co.uk/business/fdl-europe-2021-extreme-events">2</a>

              <p></p>
              <p>We introduce the RaVÆn system, a lightweight, unsupervised approach for change detection in satellite data based on Variational Auto-Encoders (VAEs) with the specific purpose of on-board deployment. It flags changed areas to prioritise for downlink, shortening the response time. We show that the proposed method outperforms pixel-wise baselines and we test it on resource-limited hardware. We also release the annotated dataset of extreme events. Work conducted at the <a href="https://fdleurope.org/fdl-europe-2021" title="Frontier Development Lab, a research accelerator by ESA, NASA, Oxford University and others.">FDL 2021</a>. In 2023 our model was tested on-board the D-Orbit's ION satellite which we report in the <a href="https://arxiv.org/abs/2307.08700">paper published at IGARSS 2023</a> - in addition, we showcase training of Machine Learning models on-board of the satellites (read more about it <a href="https://www.ox.ac.uk/news/2023-07-28-researchers-successfully-train-machine-learning-model-outer-space-first-time">here</a>).
			  </p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_fdl_aihadr_image'>
                  <img class="bigimg" src='images/paper_fdl_extreme_events_b_predictions.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_fdl_extreme_events_a_changes.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_fdl_aihadr_start() { document.getElementById('p_fdl_aihadr_image').style.opacity = "1"; }
                function p_fdl_aihadr_stop() { document.getElementById('p_fdl_aihadr_image').style.opacity = "0"; }
                p_fdl_aihadr_stop()
              </script>
            </td>

          </tr> 
<!-- / paper -->
        </tbody></table>

        <table><tbody>
<!-- paper -->
          <tr onmouseout="p_change_stop()" onmouseover="p_change_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_change_image'>
                  <img class="bigimg" src='images/paper_activechangedetection_prediction.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_activechangedetection.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_change_start() { document.getElementById('p_change_image').style.opacity = "1"; }
                function p_change_stop() { document.getElementById('p_change_image').style.opacity = "0"; }
                p_change_stop()
              </script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle">
		    
			  <a href="https://arxiv.org/abs/2008.11201">
              <papertitle>Deep Active Learning in Remote Sensing for data efficient Change Detection</papertitle>
			  </a>
              
              <br>
              <strong>Vít Růžička</strong>, 
			  <a href="https://igp.ethz.ch/personen/person-detail.html?persid=253653">Stefano D'Aronco</a>, 
			  <a href="https://igp.ethz.ch/personen/person-detail.html?persid=186562">Jan Dirk Wegner</a>, 
			  <a href="https://igp.ethz.ch/personen/person-detail.html?persid=143986">Konrad Schindler</a>
              <br>
			  <em>ECML/PKDD 2020 workshop - Machine Learning for Earth Observation</em>, 2020, <strong>Best Paper Award</strong>
              <br>
              <a href="https://github.com/previtus/ChangeDetectionProject">code</a>
	    /
			  <a href="https://colab.research.google.com/github/previtus/ChangeDetectionProject/blob/master/demo/_ChangeDetection_prediction_example.ipynb" title="Inference demo, showing results of a pre-trained Change Detection model." class="trigger">colab demo</a><span id="pop-up" style="width: 400px;"><b>Example of inference:</b><br>&nbsp;<img src="images/paper_activechangedetection_colabdemo.png" width=400px><br><em>Figure shows aerial images from years 2012 (left), 2015 (middle) and the predicted change label (right).&nbsp;</em></span>
        /
              <a href="data/presentation_DeepActiveLearningForChangeDetection_MACLEAN2020.pdf" class="trigger">presentation slides</a><span id="pop-up" style="width: 400px;"><b>Presentation at MACLEAN'20:</b><br>&nbsp;<img src="data/presentation_DeepActiveLearningForChangeDetection_MACLEAN2020.png" width=400px></span>
        /
              <a href="https://www.youtube.com/watch?v=RTBaOuyE7oI">video from MACLEAN'20</a>

              <p></p>
              <p>We investigate active learning in the context of deep neural networks for change detection and map updating. For this task we propose a Siamese version of the U-Net model and test two approaches in model uncertainty prediction (model ensembles and Monte Carlo Batch Normalization). Iteratively selecting the most uncertain samples for annotation, we reach the same performance as a model supervised with a large fully annotated training set with approx. 99% fewer annotated samples.</p>
            </td>
          </tr> 
<!-- / paper -->
        </tbody></table>
        <table><tbody>
<!-- paper -->
          <tr onmouseout="p_fast4k_stop()" onmouseover="p_fast4k_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
			  <a href="https://arxiv.org/abs/1810.10551">
                 <papertitle>Fast and accurate object detection in high resolution 4K and 8K video using GPUs</papertitle>
			  </a>
              <br>
              <strong>Vít Růžička</strong>,
              <a href="https://users.ece.cmu.edu/~franzf/">Franz Franchetti</a>
              <br>
			  <em>IEEE High Performance Extreme Computing Conference</em>, 2018, <strong>Best Paper Finalist</strong>
              <br>
              <a href="https://www.youtube.com/watch?v=07wCxSItnAk">video</a>
        /
              <a href="https://github.com/previtus/AttentionPipeline">code</a>
        /
              <a href="https://www.ece.cmu.edu/news-and-events/story/2018/11/franchetti-object-detection.html">media 1</a>, <a href="https://techxplore.com/news/2018-11-4k-8k-video-gpus.html">2</a>
        /
              <a href="data/presentation_FastHighResObjectDet_HPEC2018.pdf" class="trigger">presentation at HPEC'18</a><span id="pop-up" style="width: 400px;"><b>Presentation at HPEC'18:</b><br>&nbsp;<img src="data/presentation_FastHighResObjectDet_HPEC2018.gif" width=400px></span>
              <p></p>
              <p>Paper in which we scale up the YOLO v2 object detection model to process video of 4K-8K resolution in 3-6 fps using GPUs. We suggest a two-stage processing pipeline which allows us to ignore some areas of the image. This is much faster than processing the whole image yet retains 98% of the accuracy on a real-world video footage dataset.</p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_fast4k_image'>
                  <img class="bigimg" src='images/paper_fast4kdetection_statues.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_fast4kdetection.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_fast4k_start() { document.getElementById('p_fast4k_image').style.opacity = "1"; }
                function p_fast4k_stop() { document.getElementById('p_fast4k_image').style.opacity = "0"; }
                p_fast4k_stop()
              </script>
            </td>

          </tr> 
<!-- / paper -->
        </tbody></table>


        <table><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
			  <div class="heading">Featured artworks</div>
              <p>I always found art to be a way of exploring and communicating ideas, getting to understand or describe the unknown. In a way scientific work has similar goals but uses different language and methods. On this track I am co-organizing the yearly <a href="https://artsci.ethz.ch/" title="ArtSci is a community at ETH Zurich organizing yearly exhibitions exploring this intersection, communicating science with arts and connecting like-minded people. I am part of the organizing team. Check it out and participate!">ArtSci</a> exhibition at ETH.
              </p>
              <p>My own creative practice started with analog photography (manual and slow process of taking and developing pictures in a darkroom) and later got mixed in with Machine Learning. Can an automatic programmed or trained process be creative on its own? Perhaps not, but with a bit of work and understanding, it can be used as a tool of creative expression. Great examples of this can be seen in the neurography of <a href="http://quasimondo.com/" class="trigger">Mario Klingemann</a><span id="pop-up" style="width: 400px;"><b>Mario Klingemann - Memories of Passersby I, 2018:</b><br>&nbsp;<img src="images/illustration_marioklingemann.jpg" width=400px><br><em>Source: aiartists.org/mario-klingemann</em></span>, dataset handling of <a href="http://annaridler.com/" class="trigger">Anna Ridler</a><span id="pop-up" style="width: 400px;"><b>Anna Ridler - Myriad (Tulips), 2018:</b><br>&nbsp;<img src="images/illustration_annaridlerdatasets.jpg" width=400px><br><em>&nbsp;</em></span>, domain transfers of <a href="http://memo.tv/" class="trigger">Memo Akten</a><span id="pop-up" style="width: 400px;"><b>Memo Akten - Learning to See (Gloomy Sunday), 2017:</b><br>&nbsp;<img src="images/illustration_learningtosee.jpg" width=400px><br><em>Image reconstructed using a model trained on particular visual dataset.</em></span> or lectures by <a href="https://genekogan.com/">Gene Kogan</a>. If you would like to know more, you can hear me introducing this area in <a href="https://www.youtube.com/watch?v=b6bjeelzB5c" class="trigger">a video recording</a><span id="pop-up" style="width: 600px;"><b>Slides from the first lecture:</b><br>&nbsp;<img src="images/cci_artml_introslide.gif" width=600px><br><em>Introductory session exploring the intersections of Art and Machine Learning.&nbsp;</em></span> of my first class of Exploring Machine Intelligence at UAL.
              </p>

			  
            </td>
          </tr>
        </tbody></table>

        <table><tbody>
<!-- artwork -->
          <tr onmouseout="a_onesol_stop()" onmouseover="a_onesol_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://www.ji-hlava.com/filmy/jeden-sol-v-zivote-curiosity">
                 <papertitle>One Sol in the Life of Curiosity</papertitle>
        </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
        <em>Ji.hlava International Documentary Film Festival</em>, <strong>Special Mention for Best Czech Experimental Documentary Film 2023</strong>
              <br>
              <a href="https://www.ji-hlava.com/filmy/jeden-sol-v-zivote-curiosity">festival</a> / <a href="https://www.ji-hlava.com/novinky/vitezne-filmy-a-dalsi-ceny-27-nbsp-ji-hlavy">award</a> / <a href="https://www.cs.ox.ac.uk/news/2207-full.html">media</a>
              <p></p>
              <p> A short experimental film made about AI with AI. It was premiered at the Ji.hlava IDFF 2023 with this synopsis: <em>"24 hours, 39 minutes and 35 seconds. One Sol, during which the author lets us empathically experience the inner and outer journey of an aging rover on Mars, whose view of the great unknown tells us much more about ourselves than any scientific research."</em>
              </p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_onesol_image'>
                  <img class="bigimg" src='images/artwork_onesolinthelifeofcuriosity.gif' width="256"></div> <!--make into a gif?-->
                <img class="bigimg" src='images/artwork_onesolinthelifeofcuriosity.jpg' width="256">
              </div>
              <script type="text/javascript">
                function a_onesol_start() { document.getElementById('a_onesol_image').style.opacity = "1"; }
                function a_onesol_stop() { document.getElementById('a_onesol_image').style.opacity = "0"; }
                a_onesol_stop()
              </script>
            </td>

          </tr> 
<!-- / artwork -->
        </tbody></table>
        <table><tbody>
<!-- artwork -->
          <tr onmouseout="a_supersupersuperres_stop()" onmouseover="a_supersupersuperres_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_supersupersuperres_image'>
                  <img class="bigimg" src='images/artwork_supersupersuperres.gif' width="256"></div>
                <img class="bigimg" src='images/artwork_supersupersuperres.jpg' width="256">
              </div>
              <script type="text/javascript">
                function a_supersupersuperres_start() { document.getElementById('a_supersupersuperres_image').style.opacity = "1"; }
                function a_supersupersuperres_stop() { document.getElementById('a_supersupersuperres_image').style.opacity = "0"; }
                a_supersupersuperres_stop()
              </script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle">
              <a href="https://neuripscreativityworkshop.github.io/2021/">
			    <papertitle>Super Super Super Resolution</papertitle>
              </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
			  <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2021
              <br>
              <a href="https://neuripscreativityworkshop.github.io/2021/#/gallery">workshop gallery</a> / <a href="https://youtu.be/MtWk2GoHX9A?t=242">video</a> / <a href="https://github.com/previtus/SuperSuperSuperResolution">code</a>
              <p></p>
              <p>This project explores what happens when we use super resolution models to enhance our data. Recorded reality is more and more encoded and mixed with the artefacts of the neural age.  This offers possibilities for creative expression, as long as these enhancements are in our hands. We ask alongside with "The end" screens: imagine the possible futures, what happens next?</p>
            </td>
          </tr> 
<!-- / artwork -->
        </tbody></table>
        <table><tbody>
<!-- artwork -->
          <tr onmouseout="a_latentrider_stop()" onmouseover="a_latentrider_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
			  <a href="https://computervisionart.com/pieces2021/latent-rider/">
                 <papertitle>Latent Rider</papertitle>
			  </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
			  <em>CVPR, Computer Vision Art Gallery</em>, 2021
              <br>
              <a href="https://computervisionart.com/pieces2021/latent-rider/">Computer Vision Art Gallery</a> / <a href="https://www.youtube.com/watch?v=up62dRHqpzw">video</a>
              <p></p>
              <p>This is a short experimental film which explores the latent space of generative models trained on my own collected and curated selections of scenes. The concept of film editing is replaced by escalating jumps in the latent space, montage of feature vectors and sequences based on similarity rather than time. Imagery is reinterpreted and reordered following a compressed form.</p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_latentrider_image'>
                  <img class="bigimg" src='images/artwork_latentrider.gif' width="256"></div>
                <img class="bigimg" src='images/artwork_latentrider.jpg' width="256">
              </div>
              <script type="text/javascript">
                function a_latentrider_start() { document.getElementById('a_latentrider_image').style.opacity = "1"; }
                function a_latentrider_stop() { document.getElementById('a_latentrider_image').style.opacity = "0"; }
                a_latentrider_stop()
              </script>
            </td>

          </tr> 
<!-- / artwork -->
        </tbody></table>
        <table><tbody>
<!-- artwork -->
          <tr onmouseout="a_latentjungle_stop()" onmouseover="a_latentjungle_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_latentjungle_image'>
                  <img class="bigimg" src='images/artwork_latentjunglenips_neg.jpg' width="256"></div>
                <img class="bigimg" src='images/artwork_latentjunglenips.jpg' width="256">
              </div>
              <script type="text/javascript">
                function a_latentjungle_start() { document.getElementById('a_latentjungle_image').style.opacity = "1"; }
                function a_latentjungle_stop() { document.getElementById('a_latentjungle_image').style.opacity = "0"; }
                a_latentjungle_stop()
              </script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle">
              <a href="http://www.aiartonline.com/highlights/vit-ruzicka/">
			    <papertitle>Latent Jungle</papertitle>
              </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
			  <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2019, <strong>Highlight</strong>
              <br>
              <a href="http://www.aiartonline.com/highlights/vit-ruzicka/">gallery</a>
              <p></p>
              <p>A neuro-photographic collage playing with the typography of Amazonian jungle patterns, shapes and textures and their reinterpretation using generative neural networks and the material properties of Super8 analog film. Digital generative models as a extension of a limited number of film frames. Analog film footage as a mode of interaction with the medium inside a darkroom with photographic paper and scissors.</p>
            </td>
          </tr> 
<!-- / artwork -->
        </tbody></table>
        <table><tbody>
<!-- artwork -->
          <tr onmouseout="a_uncannyvaley_stop()" onmouseover="a_uncannyvaley_start()">
            <td style="padding:20px;width:60%;vertical-align:middle">
			  <a href="http://www.aiartonline.com/design-2019/vit-ruzicka-alexander-nikolas-walzer-nizar-taha/">
                 <papertitle>Uncanny Valleys: Generative landscapes</papertitle>
			  </a>
              <br>
              <strong>Vít Růžička</strong>, Alexander Nikolas Walzer, Nizar Taha
              <br>
			  <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2019
              <br>
              <a href="http://www.aiartonline.com/design-2019/vit-ruzicka-alexander-nikolas-walzer-nizar-taha/">gallery</a>
              <p></p>
              <p>In this project we generate endless non-existent variation of 3D patches of landscape with deep learning models trained on the features of real-world landscape. The name of the project is based on the works of Ernst Jentsch <em>"On the Psychology of the Uncanny"</em> and Masahiro Mori <em>"The Uncanny Valley"</em>, which characterize the <em>"uncanny"</em> as a mental state which occurs when one is not able to distinguish between the imagined and the real or between the dead and the living. Generated samples resemble the real, but are in fact a reimagination of the original dataset.</p>
            </td>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_uncannyvaley_image'>
                  <img class="bigimg" src='images/artwork_uncannyvalleys_sm.gif' width="256"></div>
                <img class="bigimg" src='images/artwork_uncannyvalleys_single.jpg' width="256">
              </div>
              <script type="text/javascript">
                function a_uncannyvaley_start() { document.getElementById('a_uncannyvaley_image').style.opacity = "1"; }
                function a_uncannyvaley_stop() { document.getElementById('a_uncannyvaley_image').style.opacity = "0"; }
                a_uncannyvaley_stop()
              </script>
            </td>

          </tr> 
<!-- / artwork -->
        </tbody></table>
        <table><tbody>
<!-- artwork -->
          <tr onmouseout="p_myths_stop()" onmouseover="p_myths_start()">
            <td style="padding:20px; width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='p_myths_image'>
                  <img class="bigimg" src='images/paper_mythsfakenews_detail.jpg' width="256"></div>
                <img class="bigimg" src='images/paper_mythsfakenews.jpg' width="256">
              </div>
              <script type="text/javascript">
                function p_myths_start() { document.getElementById('p_myths_image').style.opacity = "1"; }
                function p_myths_stop() { document.getElementById('p_myths_image').style.opacity = "0"; }
                p_myths_stop()
              </script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1908.01760.pdf">
                <papertitle>The Myths of Our Time: Fake News</papertitle>
              </a>
              <br>
              <strong>Vít Růžička</strong>, 
        <a href="https://www.kangeunsu.com/">Eunsu Kang</a>, 
        <a href="http://gan-systems.com/">David Gordon</a>, Ankita Patel, <a href="http://jacquifashimpaur.com/">Jacqui Fashimpaur</a>, <a href="http://www.manzil.ml/">Manzil Zaheer</a>
              <br>
        <em>International Symposium on Electronic Art</em>, 2019<br>
              <a href="http://www.newsby.ml/">project page</a>
        /
              <a href="https://github.com/previtus/fake_news_generation_mark_I">code</a>
        /
              <a href="data/presentation_MythsFakeNews_ISEA2019.pdf" class="trigger">presentation at ISEA'19</a><span id="pop-up" style="width: 400px;"><b>Presentation at ISEA'19:</b><br>&nbsp;<img src="data/presentation_MythsFakeNews_ISEA2019.gif" width=400px></span>

        <br>
        <br>
        <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2018<br>
        <a href="http://www.aiartonline.com/community/vit-ruzicka-eunsu-kang-david-gordon-ankita-patel-jacqui-fashimpaur-manzil-zaheer/" title="as an artwork submitted to the NeurIPS Workshop on Machine Learning for Creativity and Design">art gallery</a>
              <p></p>
              <p>We use LSTM models to generate fake newspaper articles focusing on areas often targetted as the contents of fake news (topics such as politics or fake news themselves). While the purpose of most fake news is misinformation and political propaganda, we explore it as a new type of myth created in the age of internet identities. These generated articles serve as a mirror and can give us insight into people’s hidden fear and desire similir to myths, folk tales or urban legends.</p>
            </td>
          </tr> 
<!-- / artwork -->

        </tbody></table>

        <table><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
			  <div class="heading">Teaching</div>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img class="smallimg" src="images/ox_ml_cdt_aims.jpg" width=180px></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://gbaydin.github.io/teaching/ml-aims-mt2023.html">
                <papertitle>Machine Learning, AIMS</papertitle>
              </a>
              <br>
              Lecturer: Atılım Güneş Baydin, Practicals: A. Tuan Nguyen, <strong>Vít Růžička</strong>
              <br>
        <em>University of Oxford - CDT in Autonomous Intelligent Machines and Systems</em>, 2022 and 2023
              <br>
              <a href="https://gbaydin.github.io/teaching/ml-aims-mt2023.html">course webpage</a>
        /
              <a href="https://github.com/gbaydin/ml-aims-mt2023">lab materials</a>
              <p></p>
              <p>Ox, CDT AIMS - DPhil course, practicals</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img class="smallimg" src="images/toi_example.png" width=180px></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://github.com/previtus/TOI_2023">
                <papertitle>Things of the Internet</papertitle>
              </a>
              <br>
              Andrew Markham, <strong>Vít Růžička</strong>
              <br>
        <em>University of Oxford - Computer Science, Software Engineering</em>, 2022 and 2023
              <br>
              <a href="https://www.cs.ox.ac.uk/softeng/subjects/TOI.html">course webpage</a>
        /
              <a href="https://github.com/previtus/TOI_2023">lab materials</a>
              <p></p>
              <p>Ox, CS - Professional Masters course, labs</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img class="smallimg" src="images/cci_ai4media.jpg" width=180px></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
                <papertitle>Artificial Intelligence for the Media - <a href="https://github.com/previtus/cci_AI_for_the_Media">20/21</a>, <a href="https://github.com/previtus/cci_AI_for_the_Media_2022">21/22</a></papertitle>

              <br>
              Louis McCallum, Josh Murr, <strong>Vít Růžička</strong>
              <br>
        <em>University of the Arts London - Creative Computing Institute</em>, 2021-22
              <br>
              <a href="https://github.com/previtus/cci_AI_for_the_Media">class page 20/21</a>
        /
              <a href="https://github.com/previtus/cci_AI_for_the_Media_2022">class page 21/22</a>

              <p></p>
              <p>UAL, CCI - MSc course "IU000133 Artificial Intelligence for the Media"</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img class="smallimg" src="images/cci_artml.gif" width=180px></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://github.com/previtus/cci_exploring_machine_intelligence">
                <papertitle>Exploring Machine Intelligence</papertitle>
              </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
        <em>University of the Arts London - Creative Computing Institute</em>, 2020
              <br>
              <a href="https://www.youtube.com/playlist?list=PLCIVpmFkFKQ88lzWtYW2MCwqXofhkzqgt">video playlist</a>
        /
              <a href="https://github.com/previtus/cci_exploring_machine_intelligence">class page</a>
              <p></p>
              <p>UAL, CCI - MSc course "IU000128 Coding Three: Exploring Machine Intelligence"</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img class="smallimg" src="images/cci_math.gif" width=180px></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://github.com/previtus/cci_data_maths_methods">
                <papertitle>Data, Math and Methods</papertitle>
              </a>
              <br>
              <strong>Vít Růžička</strong>
              <br>
        <em>University of the Arts London - Creative Computing Institute</em>, 2020
              <br>
              <a href="https://www.youtube.com/playlist?list=PLCIVpmFkFKQ9_0oVbmZ8Nln-3FP3_3aIz">video playlist</a>
        /
              <a href="https://github.com/previtus/cci_data_maths_methods">class page</a>
              <p></p>
              <p>UAL, CCI - BSc Year 1 course "Data, Math and Methods"</p>
            </td>
          </tr>

        </tbody></table>




        <table><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Webpage design from <a style="font-size:small;" href="https://jonbarron.info/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </tbody></table>


  <script type="text/javascript" src="js/custom.js"></script>

  <!-- maybe use https://clustrmaps.com/add ? or Google Analytics? -->

</body>

</html>
